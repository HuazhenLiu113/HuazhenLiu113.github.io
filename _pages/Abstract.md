<span class='anchor' id='abstract'></span>

# High-Accuracy Phase Unwrapping Based on Binarized Wrap Count
Spatial phase unwrapping is essential for converting wrapped phase fringes into a continuous unwrapped phase map, which is critical for various high-precision measurement technologies. The accuracy of phase unwrapping directly affects measurement precision. Recently, deep learning-based phase unwrapping has emerged as a promising alternative to traditional methods, primarily due to its strong resilience against noise. However, existing approaches often struggle to produce consistent results, limiting their practical applicability. This study introduces Binarized Wrap Count Phase Unwrapping (BWCPU), a novel method that utilizes neural networks to analyze phase gradient structures through binarized wrap counts. This approach reduces prediction complexity while ensuring accurate phase segmentation. In structured light surface measurements, BWCPU significantly decreases misinterpretations in noisy conditions, achieving a remarkable 76.9% improvement over leading deep learning-based wrap-count estimation methods. Furthermore, by employing a stitching algorithm known as unidirectional optimal seam stitching, BWCPU extends its capabilities to handle 1024×1024 patterns, showcasing its potential for high-precision measurements in noisy environments.

# Motion-induced phase shift for dynamic structured light measurement
Structured light 3D shape measurement is extensively utilized in semiconductor inspection, smart manufacturing, and biomedical imaging due to its rapid measurement speed, high precision, and versatile applicability to different objects. However, the traditional implementations of this method often require that the object remains static while recording the phase-shifting structured light images, which limits the adaptability of dynamic measurement. Here, we propose a dynamic 3D shape measurement using structured light based on motion-induced phase shift (MIPS). As the object moves, the surface features distort the fringe pattern, resulting in a phase shifting effect. By employing the MIPS method, we can determine the phase even in the situations where the knowledge of phase shifting conditions is not accurate. This enables the acquisition of the 3D topography of the object surface with a high level of precision. Experimental results demonstrate that the MIPS method can accurately measure the 3D shape of objects moving as fast as 100 mm/s, with a relative discrepancy of less than 0.23%.

# High frame-rate reconfigurable diffractive neural network based on superpixels
The existing implementations of reconfigurable diffractive neural network rely on both a liquid crystal spatial light modulator and a digital micromirror device, which results in the complexity in the alignment of optical system and constrained computational speed. Here, we propose a superpixel diffractive neural network that leverages solely a digital micromirror device to control neuron bias and connection. This approach considerably simplifies the optical system and achieves an computational speed of 326Hz per neural layer. We validate our method through experiments in digit classification, achieving an accuracy of 82.6%, and action recognition, attaining a perfect accuracy of 100%. Our findings demonstrate the effectiveness of the superpixel diffractive neural network in simplifying the optical system and enhancing computational speed, opening new possibilities for real-time optical information processing applications.

# Large field of view Shack-Hartmann wavefront sensor based on high-density lens transfer function retrieval
The Shack-Hartmann wavefront sensor (SHWS) is known for its high accuracy and robust wavefront sensing capabilities. However, conventional compact SHWS confronts limitations in measuring field-of-view to meet emerging applications’ increasing demands. Here, we propose a high-density lens transfer function retrieval (HDLTR)-based SHWS to expand its field-of-view. In HDLTR-SHWS, an additional lens is introduced into the measurement system, which converges input wavefront with large aperture onto detectable aperture of sensor. A densely sampling set of phase delays is employed to retrieve the transfer function of the lens and to isolate lens distortion. Then, an accurate error compensation model is established to suppress errors introduced by the lens distortion, which is used to accurately demodulate the convergent wavefront. We also utilize a global spot matching method to reconstruct the converged wavefront with a large dynamic range. Our experimental results demonstrate that the HDLTR-SHWS expands the field-of-view of SHWS by a factor of 24.9 and achieves an accuracy of less than 1/80λ.
